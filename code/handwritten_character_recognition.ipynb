{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEF Project - Kapakki Lo\n",
    "\n",
    "Recognizing Chinese Handwritten Characters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be implementing a neural network model to recognize different Chinese Characters in the dataset found here:\n",
    "\n",
    "https://www.kaggle.com/datasets/pascalbliem/handwritten-chinese-character-hanzi-datasets?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print('Tensorflow version:',tf.__version__)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import os\n",
    "print('Keras version:', tf.keras.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparing the Dataset\n",
    "\n",
    "Recognizing 7000+ chinese characters would definitely not be a good idea, as that would cause the computer to go up into flames.<br>\n",
    "This is why we will be training the neural network to find **features** from the character, so as to obtain the ChangJie input values for the character.\n",
    "<br><br>\n",
    "\n",
    "This is the page I used to find suitable datasets:<br>\n",
    "https://en.wikipedia.org/wiki/Cangjie_input_method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the path the training data is located\n",
    "ROOT_PATH = \"\"\n",
    "ORGANIZED_DATA = ROOT_PATH + \"\"\n",
    "TRAINING_DATA = ROOT_PATH + \"\"\n",
    "\n",
    "\n",
    "class character:\n",
    "    name = \"\"\n",
    "\n",
    "    def __init__(self, name, data):\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        \n",
    "    def find_characters(self):\n",
    "        data = self.data\n",
    "        for datum in data:\n",
    "            # For each character type in the list, we would check if it is found in the dataset.\n",
    "            # If it is not found, then we would have to add the data in ourselves.\n",
    "            try:\n",
    "                # 1. Try Opening folder\n",
    "                items = \n",
    "                # 2. Since folder is found, iterate through each image in the folder and copy it to the corresponding directory of the letter.\n",
    "                for item in items:\n",
    "                    # Copy it to outer directory\n",
    "                    pass\n",
    "            except Exception as e:\n",
    "                print(f\"{datum} is not found in the database. ({self.name})\")\n",
    "    \n",
    "    def train_data(self, iterations):\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "A = character(\"A\", [\"日\", \"曰\"]) # 90° rotated 日 (as in 巴)\n",
    "B = character(\"B\", [\"月\", \"冂\", \"爫\", \"冖\"]) # the top four strokes of 目; the top and top-left part of 炙, 然, and 祭; the top-left four strokes of 豹 and 貓; and the top four strokes of 骨;\n",
    "C = character(\"C\", [\"金\", \"丷\", \"八\"]) # the penultimate two strokes of 四 and 匹\n",
    "D = character(\"D\", [\"木\", \"寸\", \"才\"]) # the first two strokes of 寸 and 才; the first two strokes of 也 and 皮\n",
    "E = character(\"E\", [\"水\", \"氵\", \"又\"]) # the last five strokes of 暴 and 康\n",
    "F = character(\"F\", [\"火\", \"小\", \"灬\"]) # the first three strokes in 當 and 光\n",
    "G = character(\"G\", [\"土\", \"士\"])\n",
    "\n",
    "H = character(\"H\", [\"竹\", \"⺮\", \"㇀\", \"㇒\"])\n",
    "I = character(\"I\", [\"戈\", \"广\", \"厶\", \"㇔\"])\n",
    "J = character(\"J\", [\"十\", \"宀\"])\n",
    "K = character(\"K\", [\"大\", \"乂\", \"疒\"]) #  first two strokes of 右\n",
    "L = character(\"L\", [\"中\", \"衤\"]) # Vertical stroke; first four strokes of 書 and 盡\n",
    "M = character(\"M\", [\"一\", \"厂\", \"工\"])\n",
    "N = character(\"N\", [\"弓\"]) # Crossbow and the hook\n",
    "\n",
    "O = character(\"O\", [\"人\", \"亻\"]) # The dismemberment; the first two strokes of 丘 and 乓; the first two strokes of 知, 攻, and 氣; and the final two strokes of 兆\n",
    "P = character(\"P\", [\"心\", \"忄\", \"勹\", \"㇃\", \"⺗\", \"匕\", \"七\"])\n",
    "Q = character(\"Q\", [\"手\", \"扌\"])\n",
    "R = character(\"R\", [\"口\"])\n",
    "\n",
    "S = character(\"S\", [\"尸 \", \"匚\", \"㇕\", \"㇆\", \"㇁\"]) # the first four strokes of 長 and 髟\n",
    "T = character(\"T\", [\"廿\", \"艹\"]) # ....\n",
    "U = character(\"U\", [\"山\"]) # Three-sided enclosure with an opening on the top\n",
    "V = character(\"V\", [\"女\", \"𧘇\"])\n",
    "W = character(\"W\", [\"田\"]) # as well as any four-sided enclosure with something inside it, including the first two strokes in 母 and 毋\n",
    "X = character(\"X\", [\"金\"])\n",
    "Y = character(\"Y\", [\"卜\", \"辶\"]) # The 卜 shape and rotated forms, the first two strokes in 斗\n",
    "Z = character(\"Z\", [\"Z: N/A\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = [A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z]\n",
    "\n",
    "for char in characters:\n",
    "    char.train_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of an image: {x_train[0].shape}')\n",
    "print(f'Max pixel value: {x_train.max()}')\n",
    "print(f'Min pixel value: {x_train.min()}')\n",
    "print(f'Classes: {np.unique(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of labels\n",
    "\n",
    "text_labels = [\"日\",\n",
    "             \"月\",\n",
    "             \"金\",\n",
    "             \"木\",\n",
    "             \"水\",\n",
    "             \"火\", \n",
    "             \"土\",\n",
    "             \"竹\",\n",
    "             \"戈\",\n",
    "             \"十\",\n",
    "             \"大\",\n",
    "             \"中\",\n",
    "             \"一\",\n",
    "             \"弓\",\n",
    "             \"人\",\n",
    "             \"心\",\n",
    "             \"手\",\n",
    "             \"口\",\n",
    "             \"尸\",\n",
    "             \"廿\",\n",
    "             \"山\",\n",
    "             \"女\",\n",
    "             \"田\",\n",
    "             \"難\",\n",
    "             \"卜\",\n",
    "             \"Z\"\n",
    "             ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6d593ce05fe66d054d2fad866f7bd21bb2485f729d27c4d3b4d2d93406a9b2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
